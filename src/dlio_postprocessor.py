import os
import re
import json
import numpy as np
import pandas as pd
from statistics import mean, median, stdev, quantiles
from src.utils.argument_parser import str2bool

import argparse

class DLIOPostProcessor:
    def __init__(self, args) -> None:
        self.args = args
        self.outdir = self.args.output_folder
        self.comm_size = self.args.num_proc
        self.epochs = self.args.epochs

        self.do_eval = self.args.do_eval
        self.do_checkpoint = self.args.checkpoint

        self.batch_size = self.args.batch_size
        self.batch_size_eval = self.args.batch_size_eval

        self.iostat_file = os.path.join(self.outdir, 'iostat.json')
        # Establish the list of files that should have been generated by DLIOBenchmark
        self.files_overall = ['epoch_time_ranges.csv']
        self.files_batch_loading_times = []
        self.files_batch_processing_times = []

        if self.do_eval:
            self.files_overall.append('eval_time_ranges.csv')
            self.files_eval_batch_loading_times = []
            self.files_eval_batch_processing_times = []

        if self.do_checkpoint:
            self.files_overall.append('ckpt_time_ranges.csv')

        for rank in range(self.comm_size):
            self.files_batch_loading_times.append(f'{rank}_time_to_load_train_batch.csv')
            self.files_batch_processing_times.append(f'{rank}_time_to_process_train_batch.csv')
            if self.do_eval:
                self.files_batch_loading_times.append(f'{rank}_time_to_load_eval_batch.csv')
                self.files_batch_processing_times.append(f'{rank}_time_to_process_eval_batch.csv')

        # Overall report statistics
        self.overall_samples_per_second = 0
        self.epoch_samples_per_second = {}

        self.overall_read_bandwidth = 0
        self.overall_write_bandwidth = 0
        self.overall_read_iops = 0
        self.overall_write_iops = 0
        self.epoch_read_bandwidth = {}
        self.epoch_write_bandwidth = {}
        self.epoch_read_iops = 0
        self.epoch_write_iops = 0

        self.r_bandwidth_per_epoch = {}
        self.w_bandwidth_per_epoch = {}
        self.r_overall_bandwidth = []
        self.w_overall_bandwidth = []

        # I think it might be better to fill these two dicts up as we go along
        # and print them out at the end. That would follow the expected structure of the report
        self.overall_stats = {}
        self.per_epoch_stats = {}

        self.epochs_with_evals = set()
        self.epochs_with_ckpts = set()

    def verify_all_files_present(self):
        outdir_listing = [f for f in os.listdir(self.outdir) if os.path.isfile(os.path.join(self.outdir, f))]
        all_files = self.files_overall + self.files_batch_loading_times + self.files_batch_processing_times \
                    + self.files_eval_batch_loading_times + self.files_eval_batch_processing_times
        is_missing_file = False
        if not os.path.isfile(self.iostat_file):
                print(f"ERROR: missing necessary file: {self.iostat_file}")
        for necessary_file in all_files:
            if necessary_file not in outdir_listing:
                print(f"ERROR: missing necessary file: {os.path.join(self.outdir, necessary_file)}")
        if is_missing_file:
            exit(-1)

    def get_epoch_time_ranges(self):
        self.epoch_timeranges = {}
        self.eval_timeranges = {}
        self.ckpt_timeranges = {}

        epoch_start_end_ts = pd.read_csv(os.path.join(self.outdir, 'epoch_time_ranges.csv'), names = ['epoch_num', 'start', 'end'])
        epoch_start_end_ts.start = pd.to_datetime(epoch_start_end_ts.start)
        epoch_start_end_ts.end = pd.to_datetime(epoch_start_end_ts.end)
        if self.do_eval:
            eval_start_end_ts = pd.read_csv(os.path.join(self.outdir, 'eval_time_ranges.csv'), names = ['epoch_num', 'start', 'end'])
            eval_start_end_ts.start = pd.to_datetime(eval_start_end_ts.start)
            eval_start_end_ts.end = pd.to_datetime(eval_start_end_ts.end)
            self.epochs_with_evals = set(eval_start_end_ts['epoch_num'])
        if self.do_checkpoint:
            ckpt_start_end_ts = pd.read_csv(os.path.join(self.outdir, 'ckpt_time_ranges.csv'), names = ['epoch_num', 'start', 'end'])
            ckpt_start_end_ts.start = pd.to_datetime(ckpt_start_end_ts.start)
            ckpt_start_end_ts.end = pd.to_datetime(ckpt_start_end_ts.end)
            self.epochs_with_ckpts = set(ckpt_start_end_ts['epoch_num'])

        # For each epoch, extract the start and end times and store them in a dictionary
        for epoch in range(1, self.epochs+1):
            timerange = epoch_start_end_ts[epoch_start_end_ts['epoch_num'] == epoch]
            # Extract the values from the returned pd.Series objects
            self.epoch_timeranges[epoch] = (timerange['start'].iloc[0], timerange['end'].iloc[0])

            duration = timerange['end'].iloc[0] - timerange['start'].iloc[0]
            self.per_epoch_stats[epoch] = {
                'start': timerange['start'].iloc[0],
                'end': timerange['end'].iloc[0],
                'duration': duration.total_seconds()
            }
            # Save additional values for evals and checkpoiting, if relevant
            if self.do_eval and epoch in self.epochs_with_evals:
                timerange = eval_start_end_ts[eval_start_end_ts['epoch_num'] == epoch]
                self.eval_timeranges[epoch] = (timerange['start'].iloc[0], timerange['end'].iloc[0])
                duration = timerange['end'].iloc[0] - timerange['start'].iloc[0]
                self.per_epoch_stats[epoch]['eval'] = {
                    'start': timerange['start'].iloc[0],
                    'end': timerange['end'].iloc[0],
                    'duration': duration.total_seconds()
                }
            if self.do_checkpoint and epoch in self.epochs_with_ckpts:
                timerange = ckpt_start_end_ts[ckpt_start_end_ts['epoch_num'] == epoch]
                self.ckpt_timeranges[epoch] = (timerange['start'].iloc[0], timerange['end'].iloc[0])
                duration = timerange['end'].iloc[0] - timerange['start'].iloc[0]
                self.per_epoch_stats[epoch]['ckpt'] = {
                    'start': timerange['start'].iloc[0],
                    'end': timerange['end'].iloc[0],
                    'duration': duration.total_seconds()
                }
        
        # Get overall start, end and duration
        self.overall_stats['start'] = epoch_start_end_ts['start'].iloc[0] 
        self.overall_stats['end'] = epoch_start_end_ts['end'].iloc[-1] 
        self.overall_stats['duration'] = self.overall_stats['end'] - self.overall_stats['start'] 
        

    def get_stats(self, series):
        """
        Return a dictionary with various statistics of the given series
        """
        # Returns 99 cut points
        # We can use inclusive because we have the entire population
        percentiles = quantiles(series, n=100, method='inclusive')
        return {
            "mean": '{:.2f}'.format(mean(series)),
            "std": '{:.2f}'.format(stdev(series)),
            "min": '{:.2f}'.format(min(series)),
            "median": '{:.2f}'.format(median(series)),
            "p90": '{:.2f}'.format(percentiles[89]),
            "p99": '{:.2f}'.format(percentiles[98]),
            "max": '{:.2f}'.format(max(series))
        }

    def samples_per_second(self):

        epoch_loading_times = {}
        eval_loading_times = {}
        all_loading_times = []

        for file in self.files_batch_loading_times:
            if re.match(r'.*eval.*', file):
                saveto = eval_loading_times
                effective_batch_size = self.batch_size_eval
            else:
                saveto = epoch_loading_times
                effective_batch_size = self.batch_size

            df = pd.read_csv(os.path.join(self.outdir, file), names = ['timestamp', 'epoch_num', 'loading_time'])
            # Calculate samples per second by integer dividing batch size by loading time
            df['loading_time'] = df['loading_time'].apply(lambda x: effective_batch_size / x)
            # Group by epoch number, convert to dict
            loading_times = df.groupby('epoch_num')['loading_time'].apply(list).to_dict()
            all_loading_times += df['loading_time'].to_list()
            # Merge with overall (for each epoch, we have one file per worker)
            for epoch in loading_times.keys():
                if epoch in saveto:
                    saveto[epoch].extend(loading_times[epoch])
                else:
                    saveto[epoch] = loading_times[epoch]
        
        # Save the overall stats
        self.overall_stats['samples/s'] = self.get_stats(all_loading_times)
        self.overall_stats['loading_time'] = '{:.2f}'.format(sum(all_loading_times) / self.comm_size)
        
        # Save the per epoch/eval stats
        for epoch, loading_times in epoch_loading_times.items():
            self.per_epoch_stats[epoch]['samples/s'] = self.get_stats(loading_times)
            self.per_epoch_stats[epoch]['loading_time'] = '{:.2f}'.format(sum(loading_times) / self.comm_size)

        for epoch, loading_times in eval_loading_times.items():
            self.per_epoch_stats[epoch]['eval']['samples/s'] = self.get_stats(loading_times)
            self.per_epoch_stats[epoch]['eval']['loading_time'] = '{:.2f}'.format(sum(loading_times) / self.comm_size)


    def parse_iostat_trace(self):
        """
        Parse the iostat JSON file and return disk and cpu usage information
        """
        iotrace = json.load(open(self.iostat_file, mode='r', encoding='utf-8'))
        # TODO: Support tracing on multiple hosts, here we only get data for the first
        iotrace = iotrace['sysstat']['hosts'][0]['statistics']
        # We will convert the iostat JSON output into a Dataframe indexed by timestamp 
        # Timestamps are already in UTC (when generated from within the container)
        # Pandas can read the format, then we can convert to numpy datetime64
        cpu_stats = pd.DataFrame(columns=['timestamp', 'user', 'system', 'iowait', 'steal', 'idle'])
        # The following columns are available:
        # ['timestamp', 'disk', 'r/s', 'w/s', 'rMB/s', 'wMB/s', 'r_await', 'w_await', 'rareq-sz', 'wareq-sz', 'aqu-sz'])
        disk_stats = pd.DataFrame(columns=['timestamp', 'disk', 'r/s', 'w/s', 'rMB/s', 'wMB/s', 'r_await', 'w_await', 'aqu-sz'])
        cpu_i = 0
        disk_i = 0
        for item in iotrace:
            ts = item['timestamp']
            cpu = item['avg-cpu']
            # Combine user and nice cpu time into one for conciseness
            cpu_stats.loc[cpu_i] = [ts, cpu['user'] + cpu['nice'], cpu['system'], cpu['iowait'], cpu['steal'], cpu['idle']]
            cpu_i += 1
            # Add one row per disk
            for disk in item['disk']:
                row = [ts, disk['disk_device'], disk['r/s'], disk['w/s'], disk['rMB/s'], disk['wMB/s'], disk['r_await'], disk['w_await'], disk['aqu-sz']]
                disk_stats.loc[disk_i] = row
                disk_i += 1
        # Convert timestamp fields to datatime
        cpu_stats.timestamp = pd.to_datetime(cpu_stats.timestamp)
        disk_stats.timestamp = pd.to_datetime(disk_stats.timestamp)
        self.disk_stats = disk_stats
        self.cpu_stats = cpu_stats

    def get_series_daterange(self, series, field, start, end): 
        data = series[series[field] >= start]
        data = data[data[field] < end]
        return data

    def extract_stats_from_iostat_trace(self):
        #TODO: Change the timeranges to "logical period of training" based
        # so we can feed it a ['TRAINING, EVAL, CKPT'] or ['EPOCH', 'EVAL', 'CKPT'] etc. 
        r_overall_bandwidth = []
        w_overall_bandwidth = []
        r_overall_iops = []
        w_overall_iops = []
        r_overall_wait = []
        w_overall_wait = []
        overall_aqu_sz = []

        cpu_overall_user = []
        cpu_overall_sys = []
        cpu_overall_iowait = []
        cpu_overall_steal = []
        cpu_overall_idle = []

        def addto_and_return_stats(addto, df, stat):
            data = df[stat].to_list()
            addto += data
            return self.get_stats(data)

        def save_and_accumulate_stats(epoch, source, timeranges, stats, saveto, accumulators):
            # For each epoch, get the start and end times
            start, end = timeranges[epoch]

            # Filter the disk_stats by epoch start and end dates
            data = self.get_series_daterange(source, 'timestamp', start, end)

            stat_data = {}
            for i, stat in enumerate(stats):
                saveto[stat] = addto_and_return_stats(accumulators[i], data, stat)

        stats_to_extract = ['rMB/s', 'wMB/s', 'r/s', 'w/s', 'r_await', 'w_await', 'aqu-sz']
        accumulators = [r_overall_bandwidth, w_overall_bandwidth, r_overall_iops, w_overall_iops, r_overall_wait, w_overall_wait, overall_aqu_sz]
        cpu_stats_to_extract = ['user', 'system', 'iowait', 'steal', 'idle']
        cpu_accumulators = [cpu_overall_user, cpu_overall_sys, cpu_overall_iowait, cpu_overall_steal, cpu_overall_idle]

        # Gather the stats for each epoch, accumalating values to get the overall stats
        for epoch in range(1, self.epochs+1):
            save_and_accumulate_stats(epoch,
                                    self.disk_stats, 
                                    self.epoch_timeranges, 
                                    stats_to_extract,
                                    self.per_epoch_stats[epoch],
                                    accumulators)

            self.per_epoch_stats[epoch]['cpu'] = {}
            save_and_accumulate_stats(epoch,
                                        self.cpu_stats,
                                        self.epoch_timeranges,
                                        cpu_stats_to_extract,
                                        self.per_epoch_stats[epoch]['cpu'],
                                        cpu_accumulators)

            # Check if we performed an evaluation in this epoch and gather stats if so
            if epoch in self.epochs_with_evals:
                save_and_accumulate_stats(epoch, 
                                        self.disk_stats,
                                        self.eval_timeranges, 
                                        stats_to_extract,
                                        self.per_epoch_stats[epoch]['eval'],
                                        accumulators)

                self.per_epoch_stats[epoch]['eval']['cpu'] = {}
                save_and_accumulate_stats(epoch,
                                                self.cpu_stats,
                                                self.eval_timeranges,
                                                cpu_stats_to_extract,
                                                self.per_epoch_stats[epoch]['eval']['cpu'],
                                                cpu_accumulators)

            # Check if we performed a checkpoint in this epoch and gather stats if so
            if epoch in self.epochs_with_ckpts:
                save_and_accumulate_stats(epoch, 
                                            self.disk_stats,
                                            self.ckpt_timeranges, 
                                            stats_to_extract,
                                            self.per_epoch_stats[epoch]['ckpt'],
                                            accumulators)

                self.per_epoch_stats[epoch]['ckpt']['cpu'] = {}
                cpu_data = save_and_accumulate_stats(epoch,
                                                self.cpu_stats,
                                                self.ckpt_timeranges,
                                                cpu_stats_to_extract,
                                                self.per_epoch_stats[epoch]['ckpt']['cpu'],
                                                cpu_accumulators)

        # Compute overall stats
        self.overall_stats['rMB/s'] = self.get_stats(r_overall_bandwidth)
        self.overall_stats['wMB/s'] = self.get_stats(w_overall_bandwidth)
        self.overall_stats['r/s'] = self.get_stats(r_overall_iops)
        self.overall_stats['w/s'] = self.get_stats(w_overall_iops)
        self.overall_stats['r_await'] = self.get_stats(r_overall_wait)
        self.overall_stats['w_await'] = self.get_stats(w_overall_wait)
        self.overall_stats['aqu-sz'] = self.get_stats(overall_aqu_sz)

        self.overall_stats['cpu'] = {
            'user': self.get_stats(cpu_overall_user),
            'system': self.get_stats(cpu_overall_sys),
            'iowait': self.get_stats(cpu_overall_iowait),
            'steal': self.get_stats(cpu_overall_steal),
            'idle': self.get_stats(cpu_overall_idle)
        }

    def print_report(self):

        def print_stats(stats):
            if isinstance(stats, dict):
                stats = "\t".join(stats.values())
            return stats
                
        def print_out_section(outfile, stats_dict, has_loading=True):
            outfile.write(f"  Started:\t\t{stats_dict['start']}\n")
            outfile.write(f"  Ended:\t\t{stats_dict['end']}\n")
            outfile.write(f"  Duration (s):\t\t{stats_dict['duration']}\n")
            if has_loading:
                outfile.write(f"  Avg Loading Time Per Process (s):\t{stats_dict['loading_time']}\n\n")
            outfile.write("  \t\t\t\tmean\tstd\tmin\tmedian\tp90\tp99\tmax\n")
            outfile.write("  \t\t\t\t-------------------------------------------------------\n")
            if has_loading:
                outfile.write(f"  Samples/s:\t\t\t{print_stats(stats_dict['samples/s'])}\n")
            outfile.write(f"  Read Bandwidth (MB/s):\t{print_stats(stats_dict['rMB/s'])}\n")
            outfile.write(f"  Write Bandwidth (MB/s):\t{print_stats(stats_dict['wMB/s'])}\n")
            outfile.write(f"  Read IOPS:\t\t\t{print_stats(stats_dict['r/s'])}\n")
            outfile.write(f"  Write IOPS:\t\t\t{print_stats(stats_dict['w/s'])}\n")
            outfile.write(f"  Read Avg Latency (ms):\t{print_stats(stats_dict['r_await'])}\n")
            outfile.write(f"  Write Avg Latency (ms):\t{print_stats(stats_dict['w_await'])}\n")
            outfile.write(f"  Avg Queue Length:\t\t{print_stats(stats_dict['aqu-sz'])}\n")
            outfile.write(f"  CPU usage:\n")
            outfile.write(f"    User (%):\t\t\t{print_stats(stats_dict['cpu']['user'])}\n")
            outfile.write(f"    System (%):\t\t\t{print_stats(stats_dict['cpu']['system'])}\n")
            outfile.write(f"    IO wait (%):\t\t{print_stats(stats_dict['cpu']['iowait'])}\n")
            outfile.write(f"    Steal (%):\t\t\t{print_stats(stats_dict['cpu']['steal'])}\n")
            outfile.write(f"    Idle (%):\t\t\t{print_stats(stats_dict['cpu']['idle'])}\n\n")

        with open(os.path.join(self.outdir, "DLIO_report.txt"), 'w') as outfile:
            outfile.write("Overall\n")
            print_out_section(outfile, self.overall_stats)

            outfile.write("Detailed Report\n")

            i_eval = 1
            i_ckpt = 1
            for epoch in range(1, self.epochs+1):
                
                outfile.write(f"Epoch {epoch}\n")
                print_out_section(outfile, self.per_epoch_stats[epoch])

                # Check if we performed an evaluation in this epoch and gather stats if so
                if epoch in self.epochs_with_evals:
                    outfile.write(f"Eval {i_eval}\n")
                    print_out_section(outfile, self.per_epoch_stats[epoch]['eval'])
                    i_eval += 1
                
                # Ckpt will be missing some stats
                if epoch in self.epochs_with_ckpts:
                    outfile.write(f"Checkpoint {i_ckpt}\n")
                    print_out_section(outfile, self.per_epoch_stats[epoch]['ckpt'], False)
                    i_ckpt += 1

    def generate_report(self):
        # For each rank, gather stats
        self.verify_all_files_present()
        self.get_epoch_time_ranges()
        # Samples per second: overall and per epoch
        self.samples_per_second()
        # parse iostat report
        self.parse_iostat_trace()
        self.extract_stats_from_iostat_trace()
        self.print_report()


def main():
    """
    The main method to start the benchmark runtime.
    """
    parser = argparse.ArgumentParser(description='DLIO PostProcessor')
    
    parser.add_argument("-of", "--output-folder", default="./output", type=str,
                        help="Folder containing the output of a benchmark run.")
    parser.add_argument("-np", "--num-proc", default=1, type=int,
                        help="Number of processes that were ran.")
    parser.add_argument("-e", "--epochs", default=1, type=int,
                        help="Number of epochs to be emulated within benchmark.")
    parser.add_argument("-bs", "--batch-size", default=1, type=int,
                        help="Per worker batch size for training records.")
    parser.add_argument("-de", "--do-eval", default=False, type=str2bool,
                        help="If evaluations were simulated.")
    parser.add_argument("-bse", "--batch-size-eval", default=1, type=int,
                        help="Per worker batch size for evaluation records.")
    parser.add_argument("-c", "--checkpoint", default=False, type=str2bool,
                        help="If checkpointing was simulated")

    args = parser.parse_args()
    postproc = DLIOPostProcessor(args)
    postproc.generate_report()

if __name__ == '__main__':
    main()
    exit(0)